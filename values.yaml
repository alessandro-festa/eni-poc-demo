# Services deployed in suse-private-ai namespace with suse-private-ai release name.
# Global section
global:
  imagePullSecrets:
    - application-collection
  tls:
    # options: suse-private-ai, letsEncrypt, secret
    source: suse-private-ai
    issuerName: suse-private-ai

    # This section to be filled out when using letsEncrypt as the tls source
    letsEncrypt:
      environment: staging
      email: none@example.com
      ingress:
        class: ""

    # Additional Trusted CAs.
    # Enable this flag and add your CA certs as a secret named tls-ca-additional in the suse-private-ai namespace.
    additionalTrustedCAs: false


# Ollama subchart overrides - see the charts/ollama for additional entries
ollama:
  ingress:
    enabled: false #Disabled - ollama endpoint is internal.
  persistentVolume:
    enabled: false
    storageClass: ""
    size: 30Gi
  ollama:
    models:
      pull: []
      run: []
    gpu:
      # -- Enable GPU integration
      enabled: false

      # -- GPU type: 'nvidia' or 'amd'
      # If 'ollama.gpu.enabled', default value is nvidia
      # If set to 'amd', this will add 'rocm' suffix to image tag if 'image.tag' is not override
      # This is due cause AMD and CPU/CUDA are different images
      type: 'nvidia'

      # -- Specify the number of GPU
      # If you use MIG section below then this parameter is ignored
      number: 1

      # -- only for nvidia cards; change to (example) 'nvidia.com/mig-1g.10gb' to use MIG slice
      nvidiaResource: "nvidia.com/gpu"
      # nvidiaResource: "nvidia.com/mig-1g.10gb" # example
      # If you want to use more than one NVIDIA MIG you can use the following syntax (then nvidiaResource is ignored and only the configuration in the following MIG section is used)
      #
  runtimeClassName: ""

mlflow:
  enabled: true
    spec:
      containers:
      - name: mlflow-server
        # image: dp.apps.rancher.io/containers/mlflow:3.3.2
        image: ghcr.io/mlflow/mlflow:v3.3.2
        command: ["/bin/sh"]
        args: ["-c", "apt-get update && apt-get install -y build-essential libpq-dev && pip install psycopg2 boto3 && mlflow db upgrade postgresql://mlflow:mlflow@suseai-postgresql.suseai.svc.cluster.local:5432/mlflow && mlflow server --backend-store-uri postgresql://mlflow:mlflow@suseai-postgresql.suseai.svc.cluster.local:5432/mlflow --host 0.0.0.0 --serve-artifacts --artifacts-destination s3://mlflow"]         
        env:
          - name: AWS_ACCESS_KEY_ID
            value: mZNezGKCWJXFVmL84LCP
          - name: AWS_SECRET_ACCESS_KEY
            value: r6lPIWiniaZqWFzpihcFlNrlWkodtjzPujYzItVw
          - name: MLFLOW_S3_ENDPOINT_URL
            value: http://suseai-minio.suseai.svc.cluster.local:9000
          - name: MLFLOW_S3_IGNORE_TLS
            value: "true"
        livenessProbe:
          exec:
            command:
              - curl
              - -f
              - http://localhost:5000/
          failureThreshold: 3
          periodSeconds: 30
          timeoutSeconds: 10
        ports:
          - containerPort: 5000
            protocol: TCP
      restartPolicy: Always
minio:
  enabled: true
  mode: standalone
  ## TLS Settings for MinIO
  tls:
    enabled: false
persistence:
  enabled: true
  size: 5Gi
  resources:
    requests:
      memory: 512Mi
  rootUser: admin
  rootPassword: admin123
qdrant:
  enabled: true
postgresql:
  enabled: true
  auth:
    database: mlflow
    username: mlflow
    password: mlflow
